# witin-nn
The "witin_nn" framework, based on PyTorch, maps neural networks to chip computations and supports operators including Linear, Conv2d, and GruCell. It enables 8-12 bit quantization for inputs/outputs and weights, implementing QAT.
